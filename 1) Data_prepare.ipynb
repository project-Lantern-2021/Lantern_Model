{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수어 영상이 저장되어 있는 폴더\n",
    "video_folder = './video/'\n",
    "\n",
    "# 영상에서 추출한 프레임을 저장할 폴더\n",
    "frame_folder = './frame/'\n",
    "\n",
    "file_list = os.listdir(video_folder)\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    # 영상 파일명과 같은 new _folder 생성\n",
    "    new_folder = file_list[i][:-4]\n",
    "    new_path = frame_folder + \"{}\".format(new_folder)\n",
    "    \n",
    "    if not (os.path.isdir(new_path)):\n",
    "        # 해당 파일명과 동일한 폴더가 없으면 생성\n",
    "        os.mkdir(os.path.join(new_path))\n",
    "\n",
    "    # 영상에서 프레임 추출\n",
    "    file_name = file_list[i] \n",
    "    file_path = video_folder + file_name\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    time.sleep(5)\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        try:\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imwrite(\"{}/{}_{}.png\".format(new_path, new_folder[-4:], count), frame) \n",
    "            print('Saved %d frame' %count)\n",
    "\n",
    "            if cv2.waitKey(10) == 27:                    \n",
    "                  break\n",
    "            count += 1\n",
    "        except:\n",
    "            cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#웹캠 프레임 저장\n",
    "IMAGES_PATH = '../etc/'\n",
    "\n",
    "#직접 구현 할 수어 단어들\n",
    "labels = ['12', '15', '21', '29', '37', '45']\n",
    "number_imgs = 15\n",
    "\n",
    "#label별로 디렉토리를 만들고 uuid로 frame마다 unique idenrifier를 붙혀서 저장하기\n",
    "for label in labels:\n",
    "    os.mkdir('./{}'.format(label))\n",
    "    \n",
    "    #video capture시작(initialize webcam)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting Images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #frame을 capture\n",
    "    for imgnum in range(number_imgs):\n",
    "        ret, frame = cap.read()\n",
    "        #각 frame이 unique한 이름으로 저장되도록 uuid.uuidi() 사용\n",
    "        imagename = os.path.join(IMAGES_PATH, label, label+'-'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        #디렉토리에 이미지 저장\n",
    "        cv2.imwrite(imagename, frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    #videoCapture끝내기        \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 :  data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_folder = []\n",
    "\n",
    "for folder in os.listdir('./frame/'):\n",
    "    for file in os.listdir('./frame/{}' .format(folder)):\n",
    "        if file.split('.')[-1] == 'png' or file.split('.')[-1] == 'txt':\n",
    "            frame_folder.append(file[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 수어 영상 구분\n",
    "hungry_list = ['0227', '1056', '1812', '2741', '3569', '4415', '5253', '6093', '6929', '7762']\n",
    "hospital_list = ['0232', '1061', '1817', '2746', '3574', '4420', '5259', '6098', '6934', '7767']\n",
    "teacher_list = ['0256', '1088', '1847', '2770', '3598', '4444', '5283', '6122', '6958', '7794']\n",
    "woman_list = ['0282', '1115', '1876', '2796', '3623', '4470', '5309', '6148', '6984', '7821']\n",
    "elevator_list = ['0298', '1132', '1895', '2812', '3640', '4486', '5325', '6164', '7000', '7838']\n",
    "taxi_list = ['9088', '9219', '9249', '9384', '9410', '9572', '9725', '9897', '9925', '9992']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수어 영상 프레임의 30%만 data augumentation\n",
    "data_list = []\n",
    "img_path = './frame/{}/'\n",
    "\n",
    "for file in os.listdir(img_path):\n",
    "    if file.split('.')[-1] == 'png':\n",
    "        if file[:4] in {}_list:\n",
    "            data_list.append(file.split('.')[0])  \n",
    "            \n",
    "dark_list = random.sample(data_list, int(len(data_list)*0.30))\n",
    "dark_list_50 = dark_list[:int(len(dark_list)/2)]\n",
    "dark_list_25 = dark_list[int(len(dark_list)/2):]\n",
    "\n",
    "for file in dark_list_50:\n",
    "    src = cv2.imread(img_path+file+'.png')\n",
    "    sub_50 = cv2.subtract(src, np.array([50.0]))\n",
    "    new_filename = img_path+file+'d'\n",
    "    cv2.imwrite(new_filename+'.png', sub_50)\n",
    "    shutil.copy(img_path+file+'.txt', new_filename+'.txt')\n",
    "\n",
    "for file in dark_list_25:\n",
    "    src = cv2.imread(img_path+file+'.png')\n",
    "    sub_25 = cv2.subtract(src, np.array([25.0]))\n",
    "    new_filename = img_path+file+'d'\n",
    "    cv2.imwrite(new_filename+'.png', sub_25)\n",
    "    shutil.copy(img_path+file+'.txt', new_filename+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#웹캠 촬영 프레임 구분\n",
    "hungry_list = '9993'\n",
    "hospital_list = '9994'\n",
    "teacher_list = '9995'\n",
    "woman_list = '9996'\n",
    "elevator_list = '9997'\n",
    "taxi_list = '9998'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠 촬영 프레임 전체 data augumentation\n",
    "data_list = []\n",
    "img_path = './frame/{}/'\n",
    "\n",
    "for file in os.listdir(img_path):\n",
    "    if file.split('.')[-1] == 'png':\n",
    "        if file[:4] == {}_list:\n",
    "            data_list.append(file.split('.')[0])\n",
    "        \n",
    "dark_list = random.sample(data_list, len(data_list))\n",
    "dark_list_50 = dark_list[:int(len(dark_list)/2)]\n",
    "dark_list_25 = dark_list[int(len(dark_list)/2):]\n",
    "\n",
    "for file in dark_list_50:\n",
    "    src = cv2.imread(img_path+file+'.png')\n",
    "    sub_50 = cv2.subtract(src, np.array([50.0]))\n",
    "    new_filename = img_path+file+'d'\n",
    "    cv2.imwrite(new_filename+'.png', sub_50)\n",
    "    shutil.copy(img_path+file+'.txt', new_filename+'.txt')\n",
    "\n",
    "for file in dark_list_25:\n",
    "    src = cv2.imread(img_path+file+'.png')\n",
    "    sub_25 = cv2.subtract(src, np.array([25.0]))\n",
    "    new_filename = img_path+file+'d'\n",
    "    cv2.imwrite(new_filename+'.png', sub_25)\n",
    "    shutil.copy(img_path+file+'.txt', new_filename+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 :  data train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {}\n",
    "path = './obj/'\n",
    "word_list = os.listdir(path)\n",
    "for index in word_list:\n",
    "    file_list = []\n",
    "    for file in os.listdir(path + f'{index}'):\n",
    "        if file.split('.')[-1].lower() == 'png':\n",
    "            file_list.append(file.split('.')[0])\n",
    "    input_data[index] = file_list\n",
    "\n",
    "y = []\n",
    "for w in word_list:\n",
    "    y_sub = []\n",
    "    for i in range(0,len(input_data[w])):\n",
    "        y_sub.append(w)\n",
    "    y.append(y_sub)\n",
    "    \n",
    "X_train_list=[]\n",
    "X_test_list=[]\n",
    "\n",
    "for j in range(len(word_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        input_data[word_list[j]], y[j], test_size=0.3, random_state=42)\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "path = './'\n",
    "\n",
    "for n in range(len(word_list)):\n",
    "    # train 파일 옮기기\n",
    "    for r in range(len(X_train_list[n])):\n",
    "        #.png파일 옮기기\n",
    "        b_png= path + 'obj/{}/{}.png'.format(word_list[n], X_train_list[n][r])\n",
    "        a_png= path + 'train/{}.png'.format(X_train_list[n][r])\n",
    "        shutil.move(b_png, a_png)\n",
    "        \n",
    "    # test 파일 옮기기\n",
    "    for r in range(len(X_test_list[n])):\n",
    "        #.png파일 옮기기\n",
    "        b_png= path + 'obj/{}/{}.png'.format(word_list[n],X_test_list[n][r])\n",
    "        a_png= path + 'test/{}.png'.format(X_test_list[n][r])\n",
    "        shutil.move(b_png, a_png)\n",
    "        \n",
    "for n in range(len(word_list)):\n",
    "    # train 파일 옮기기\n",
    "    for r in range(len(X_train_list[n])):\n",
    "        #.txt파일 옮기기\n",
    "        b_txt= path + 'obj/{}/{}.txt'.format(word_list[n], X_train_list[n][r])\n",
    "        a_txt= path + 'train/{}.txt'.format(X_train_list[n][r])\n",
    "        shutil.move(b_txt, a_txt)\n",
    "        \n",
    "    # test 파일 옮기기\n",
    "    for r in range(len(X_test_list[n])):\n",
    "        #.txt파일 옮기기\n",
    "        b_txt= path + 'obj/{}/{}.txt'.format(word_list[n],X_test_list[n][r])\n",
    "        a_txt= path + 'test/{}.txt'.format(X_test_list[n][r])\n",
    "        shutil.move(b_txt, a_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 :  create train, test txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for png in os.listdir('./train/'):\n",
    "    if png.split('.')[-1] == 'png':\n",
    "        line = 'data/obj/' + png +'\\n'\n",
    "        with open('./yolo/custom_data/level_4_final/train.txt', 'a') as f:\n",
    "            f.write(line)\n",
    "            \n",
    "for png in os.listdir('./test/'):\n",
    "    if png.split('.')[-1] == 'png':\n",
    "        line = 'data/obj/' + png +'\\n'\n",
    "        with open('./yolo/custom_data/level_4_final/test.txt', 'a') as f:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 :  create names, data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(full_path_to_images + '/' + 'classes.names', 'w') as names, \\\n",
    "     open(full_path_to_images + '/' + 'classes.txt', 'r') as txt:\n",
    "    for line in txt:\n",
    "        names.write(line)  \n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(full_path_to_images + '/' + 'labelled_data.data', 'w') as data:\n",
    "    data.write('classes = ' + str(c) + '\\n')\n",
    "    data.write('train = ' + 'data' + '/' + 'train.txt' + '\\n')\n",
    "    data.write('valid = ' + 'data' + '/' + 'test.txt' + '\\n')\n",
    "    data.write('names = ' + 'data' + '/' + 'classes.names' + '\\n')\n",
    "    data.write('backup = backup')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
